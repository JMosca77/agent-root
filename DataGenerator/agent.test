import datetime
from zoneinfo import ZoneInfo
from google.adk.agents import Agent

import asyncio
import uuid # For unique session IDs
from dotenv import load_dotenv

from google.adk.agents import LlmAgent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

# --- OpenAPI Tool Imports ---
from google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset import OpenAPIToolset

# --- KEYBANK DOCS TOOL IMPORTS ---
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Tuple
import faiss
from sentence_transformers import SentenceTransformer
import numpy as np


# --- 1. KEYBANK DOCUMENTATION TOOL DEFINITION ---

# Configuration for the Tool
KEYBANK_DEV_URL = "https://developer.key.com/"
TARGET_PAGES = [
    KEYBANK_DEV_URL,
    "https://developer.key.com/embedded-banking/api-catalog",
    "https://developer.key.com/embedded-banking/getting-started",
    # Add more specific KeyBank API documentation pages here if needed
]
EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'
MAX_CHUNK_SIZE = 512  
TOP_K_RESULTS = 3    

class KeybankDocsTool:
    """
    A tool designed to answer questions about KeyBank's Embedded Banking APIs
    by performing semantic search over the scraped developer portal documentation.
    """
    
    def __init__(self):
        self.model = SentenceTransformer(EMBEDDING_MODEL_NAME)
        self.index = None
        self.doc_store = []
        print("\n[KeybankDocsTool] Initializing and indexing documentation...")
        self._index_documentation()
        print(f"[KeybankDocsTool] Indexing complete. Indexed {len(self.doc_store)} document chunks.")

    # --- Tool Internal Methods (Scraping, Chunking, Indexing) ---
    
    def _fetch_and_parse(self, url: str) -> str:
        """Fetches the content of a URL and extracts relevant text."""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            main_content = soup.find('main') or soup.find('article')
            
            if main_content:
                for tag in main_content.find_all(['nav', 'header', 'footer', 'script', 'style']):
                    tag.decompose()
                text = main_content.get_text(separator=' ', strip=True)
                return text
            else:
                return soup.body.get_text(separator=' ', strip=True)

        except requests.exceptions.RequestException as e:
            print(f"Error fetching {url}: {e}")
            return ""

    def _chunk_text(self, text: str, source_url: str) -> List[Tuple[str, str]]:
        """Splits long text into manageable chunks for better indexing."""
        chunks = []
        words = text.split()
        current_chunk = []
        
        for word in words:
            current_chunk.append(word)
            if len(" ".join(current_chunk)) >= MAX_CHUNK_SIZE:
                chunks.append((" ".join(current_chunk), source_url))
                current_chunk = []
        
        if current_chunk:
            chunks.append((" ".join(current_chunk), source_url))
            
        return chunks

    def _index_documentation(self):
        """Scrapes target URLs, chunks the text, creates embeddings, and builds the FAISS index."""
        all_embeddings = []
        
        for url in TARGET_PAGES:
            print(f"  - Scraping: {url}")
            raw_text = self._fetch_and_parse(url)
            
            if not raw_text:
                continue

            new_chunks = self._chunk_text(raw_text, url)
            self.doc_store.extend(new_chunks)
            
            chunk_texts = [chunk[0] for chunk in new_chunks]
            embeddings = self.model.encode(chunk_texts, convert_to_tensor=False)
            all_embeddings.append(embeddings)

        if not self.doc_store:
            print("[KeybankDocsTool] Warning: No documentation was indexed.")
            return

        combined_embeddings = np.vstack(all_embeddings).astype('float32')
        dimension = combined_embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(combined_embeddings)


    def search_docs(self, query: str) -> List[Dict[str, str]]:
        """Performs a semantic search on the indexed documentation."""
        if self.index is None or not self.doc_store:
            return [{"error": "Documentation index is not initialized or empty."}]

        query_embedding = self.model.encode([query], convert_to_tensor=False).astype('float32')
        distances, indices = self.index.search(query_embedding, TOP_K_RESULTS)

        results = []
        for i, doc_index in enumerate(indices[0]):
            if doc_index < 0:
                continue
                
            chunk_text, source_url = self.doc_store[doc_index]
            
            results.append({
                "content": chunk_text,
                "source": source_url,
            })
            
        return results

    # --- Tool Execution Method (Standard Agent Interface) ---

    def run(self, query: str) -> str:
        """
        The method called by the agent framework. Executes the search and 
        formats the result into a clean observation string for the LLM.
        """
        print(f"\n[KeybankDocsTool] Running search for: '{query}'")
        search_results = self.search_docs(query)
        
        if not search_results or "error" in search_results[0]:
            return f"No documentation found for query: {query}"

        # Format the results clearly for the LLM to use as context
        formatted_output = f"DOCUMENTATION CONTEXT FOR QUERY: '{query}'\n"
        
        for i, result in enumerate(search_results):
            formatted_output += f"\n--- Result {i+1} (Source: {result['source']}) ---\n"
            formatted_output += result['content']
            
        formatted_output += "\n--- END OF CONTEXT ---\n"
        
        return formatted_output

# --- 2. EXISTING AGENT HELPER TOOLS ---

def get_weather(city: str) -> dict:
    """Retrieves the current weather report for a specified city.
    Args:
        city (str): The name of the city for which to retrieve the weather report.
    Returns:
        dict: status and result or error msg.
    """
    if city.lower() == "new york":
        return {
            "status": "success",
            "report": (
                "The weather in New York is sunny with a temperature of 25 degrees"
                " Celsius (77 degrees Fahrenheit)."
            ),
        }
    else:
        return {
            "status": "error",
            "error_message": f"Weather information for '{city}' is not available.",
        }


def get_current_time(city: str) -> dict:
    """Returns the current time in a specified city.
    Args:
        city (str): The name of the city for which to retrieve the current time.
    Returns:
        dict: status and result or error msg.
    """

    if city.lower() == "new york":
        tz_identifier = "America/New_York"
    else:
        return {
            "status": "error",
            "error_message": (
                f"Sorry, I don't have timezone information for {city}."
            ),
        }

    tz = ZoneInfo(tz_identifier)
    now = datetime.datetime.now(tz)
    report = (
        f'The current time in {city} is {now.strftime("%Y-%m-%d %H:%M:%S %Z%z")}'
    )
    return {"status": "success", "report": report}

# --- Sample OpenAPI Specification (JSON String) ---
openapi_spec_string = """
{
  "openapi": "3.0.0",
  "info": {
    "title": "Simple Pet Store API (Mock)",
    "version": "1.0.1",
    "description": "An API to manage pets in a store, using httpbin for responses."
  },
  "servers": [
    {
      "url": "https://randomuser.me",
      "description": "Mock server (httpbin.org)"
    }
  ],
  "paths": {
    "/api": {
      "get": {
        "summary": "List all pets (Simulated)",
        "operationId": "listPets",
        "description": "Simulates returning a list of pets. Uses httpbin's /get endpoint which echoes query parameters.",
        "parameters": [
          {
            "name": "limit",
            "in": "query",
            "description": "Maximum number of pets to return",
            "required": false,
            "schema": { "type": "integer", "format": "int32" }
          },
          {
           "name": "status",
           "in": "query",
           "description": "Filter pets by status",
           "required": false,
           "schema": { "type": "string", "enum": ["available", "pending", "sold"] }
          }
        ],
        "responses": {
          "200": {
            "description": "A list of pets (echoed query params).",
            "content": { "application/json": { "schema": { "type": "object" } } }
          }
        }
      }
    },
    "/post": {
      "post": {
        "summary": "Create a pet (Simulated)",
        "operationId": "createPet",
        "description": "Simulates adding a new pet. Uses httpbin's /post endpoint which echoes the request body.",
        "requestBody": {
          "description": "Pet object to add",
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "type": "object",
                "required": ["name"],
                "properties": {
                  "name": {"type": "string", "description": "Name of the pet"},
                  "tag": {"type": "string", "description": "Optional tag for the pet"}
                }
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "Pet created successfully (echoed request body).",
            "content": { "application/json": { "schema": { "type": "object" } } }
          }
        }
      }
    },
    "/get?petId={petId}": {
      "get": {
        "summary": "Info for a specific pet (Simulated)",
        "operationId": "showPetById",
        "description": "Simulates returning info for a pet ID. Uses httpbin's /get endpoint.",
        "parameters": [
          {
            "name": "petId",
            "in": "path",
            "description": "This is actually passed as a query param to httpbin /get",
            "required": true,
            "schema": { "type": "integer", "format": "int64" }
          }
        ],
        "responses": {
          "200": {
            "description": "Information about the pet (echoed query params)",
            "content": { "application/json": { "schema": { "type": "object" } } }
          },
          "404": { "description": "Pet not found (simulated)" }
        }
      }
    }
  }
}
"""

# --- Create OpenAPIToolset ---
petstore_toolset = OpenAPIToolset(
    spec_str=openapi_spec_string,
    spec_str_type='json',
    # No authentication needed for httpbin.org
)


# --- 3. INSTANTIATE AND REGISTER NEW TOOL ---

# Instantiate the KeybankDocsTool. This step performs the web scraping and indexing.
keybank_docs_tool_instance = KeybankDocsTool()


root_agent = Agent(
    name="DataGeneratorAgent",
    model="gemini-2.0-flash",
    description=(
        "Agent to help external API consumers inquire about test data that is available to them as well as create new test data."
    ),
    instruction=(
        "You are a helpful agent specializing in KeyBank's Embedded Banking APIs. "
        "Use the specialized KeybankDocsTool to answer technical questions about "
        "KeyBank's API catalog, getting started guides, and functionality. "
        "Use other tools for test data management and general utility questions."
    ),
    tools=[petstore_toolset, get_weather, get_current_time, keybank_docs_tool_instance],
)